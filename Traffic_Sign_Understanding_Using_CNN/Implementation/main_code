!pip -q install torch torchvision scikit-learn seaborn


import os
import zipfile
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import torch
from torch import nn
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms

from sklearn.metrics import confusion_matrix, classification_report


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)


ZIP_NAME = "traffic_sign_small.zip"
ZIP_PATH = f"/content/{ZIP_NAME}"
ROOT_DIR = "/content/traffic_sign_small"

if not os.path.isdir(ROOT_DIR):
    if os.path.isfile(ZIP_PATH):
        print("Unzipping dataset...")
        with zipfile.ZipFile(ZIP_PATH, "r") as zf:
            zf.extractall("/content")
    else:
        raise FileNotFoundError(
            f"Could not find {ZIP_PATH}. "
            "Upload the zip to Colab or change ZIP_NAME."
        )
else:
    print("Dataset folder already present, skipping unzip.")

print("Contents of ROOT_DIR:", os.listdir(ROOT_DIR))



LABELS_CSV = os.path.join(ROOT_DIR, "labels.csv")
labels_df = pd.read_csv(LABELS_CSV)
labels_df = labels_df.sort_values("ClassId")


id_to_name = dict(zip(labels_df["ClassId"], labels_df["Name"]))
num_classes = labels_df["ClassId"].nunique()

print("\nNumber of classes:", num_classes)
print(labels_df.head())


# Images
TRAIN_DIR = os.path.join(ROOT_DIR, "traffic_Data", "DATA")
print("\nUsing image root:", TRAIN_DIR)
print("Example class folders:", os.listdir(TRAIN_DIR)[:10])

# Transform:
#  - Resize to 32x32
#  - Convert to tensor
#  - Normalize so pixel values are roughly in [-1, 1]
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5],
                         std=[0.5, 0.5, 0.5]),
])


full_dataset = datasets.ImageFolder(TRAIN_DIR, transform=transform)
folder_classes = full_dataset.classes
print("\nImageFolder classes:", folder_classes[:10])


idx_to_sign_name = {
    idx: id_to_name[int(cls_name)] for idx, cls_name in enumerate(folder_classes)
}


val_ratio = 0.2
n_total = len(full_dataset)
n_val = int(n_total * val_ratio)
n_train = n_total - n_val
train_dataset, val_dataset = random_split(full_dataset, [n_train, n_val])
print(f"\nTotal images: {n_total} | Train: {n_train} | Val: {n_val}")

batch_size = 64
train_loader = DataLoader(train_dataset, batch_size=batch_size,
                          shuffle=True, num_workers=2, pin_memory=True)
val_loader   = DataLoader(val_dataset, batch_size=batch_size,
                          shuffle=False, num_workers=2, pin_memory=True)


class SimpleCNN(nn.Module):
    """
    A small CNN with 3 conv blocks + 2 fully-connected layers.
    Input: 3x32x32 image
    - Block 1: Conv(3->32) + BN + ReLU + MaxPool  -> 32x16x16
    - Block 2: Conv(32->64) + BN + ReLU + MaxPool -> 64x8x8
    - Block 3: Conv(64->128)+ BN + ReLU + MaxPool -> 128x4x4
    Then flatten -> FC(2048->256) + ReLU + Dropout -> FC(256->num_classes)
    """
    def __init__(self, num_classes: int):
        super().__init__()
        self.features = nn.Sequential(
            # Block 1
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),   # 32x32 -> 16x16

            # Block 2
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),   # 16x16 -> 8x8

            # Block 3
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),   # 8x8 -> 4x4
        )

        self.classifier = nn.Sequential(
            nn.Flatten(),                     # 128 * 4 * 4 = 2048
            nn.Linear(128 * 4 * 4, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(256, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

model = SimpleCNN(num_classes=len(folder_classes)).to(device)
print("\nModel architecture:")
print(model)


criterion = nn.CrossEntropyLoss()                 # multi-class classification loss
optimizer = torch.optim.Adam(model.parameters(),
                             lr=1e-3)

def run_epoch(loader, train: bool):
    """
    Runs one epoch over 'loader'.
    If train=True -> updates weights.
    Returns average loss and accuracy.
    """
    if train:
        model.train()
    else:
        model.eval()

    running_loss = 0.0
    correct = 0
    total = 0

    for images, labels in loader:
        images, labels = images.to(device), labels.to(device)

        if train:
            optimizer.zero_grad()

        outputs = model(images)
        loss = criterion(outputs, labels)

        if train:
            loss.backward()
            optimizer.step()

        running_loss += loss.item() * images.size(0)
        _, preds = outputs.max(1)
        total += labels.size(0)
        correct += preds.eq(labels).sum().item()

    avg_loss = running_loss / total
    avg_acc = correct / total
    return avg_loss, avg_acc


num_epochs = 5
history = {"train_loss": [], "val_loss": [],
           "train_acc": [], "val_acc": []}

print("\nStarting training...")
for epoch in range(1, num_epochs + 1):
    train_loss, train_acc = run_epoch(train_loader, train=True)
    val_loss, val_acc     = run_epoch(val_loader,   train=False)

    history["train_loss"].append(train_loss)
    history["val_loss"].append(val_loss)
    history["train_acc"].append(train_acc)
    history["val_acc"].append(val_acc)

    print(f"Epoch {epoch:02d} | "
          f"train loss {train_loss:.4f}, acc {train_acc:.3f} | "
          f"val loss {val_loss:.4f}, acc {val_acc:.3f}")


epochs = range(1, num_epochs + 1)

plt.figure(figsize=(12,5))
# Loss
plt.subplot(1,2,1)
plt.plot(epochs, history["train_loss"], label="Train loss")
plt.plot(epochs, history["val_loss"],   label="Val loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training & Validation Loss")
plt.legend()

# Accuracy
plt.subplot(1,2,2)
plt.plot(epochs, history["train_acc"], label="Train acc")
plt.plot(epochs, history["val_acc"],   label="Val acc")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Training & Validation Accuracy")
plt.legend()

plt.tight_layout()
plt.show()


all_true = []
all_pred = []
model.eval()

with torch.no_grad():
    for images, labels in val_loader:
        images = images.to(device)
        outputs = model(images)
        _, preds = outputs.max(1)
        all_true.extend(labels.numpy().tolist())
        all_pred.extend(preds.cpu().numpy().tolist())

all_true = np.array(all_true)
all_pred = np.array(all_pred)

cm = confusion_matrix(all_true, all_pred)
print("\nConfusion matrix shape:", cm.shape)

plt.figure(figsize=(10,8))
sns.heatmap(cm, cmap="Blues", cbar=True)
plt.title("Confusion Matrix (Validation Set)")
plt.xlabel("Predicted class index")
plt.ylabel("True class index")
plt.tight_layout()
plt.show()


target_names = [idx_to_sign_name[i] for i in range(len(folder_classes))]
print("\nClassification report:")
print(classification_report(all_true, all_pred,
                            labels=range(len(folder_classes)),
                            target_names=target_names,
                            digits=3))


def show_example_predictions(loader, n_images=5):
    """
    Shows a few images from 'loader' with true and predicted labels.
    """
    model.eval()
    images, labels = next(iter(loader))        # first batch
    images, labels = images.to(device), labels.to(device)

    with torch.no_grad():
        outputs = model(images)
        _, preds = outputs.max(1)

    plt.figure(figsize=(15, 3))
    for i in range(min(n_images, images.size(0))):
        img = images[i].cpu()

        img = img * 0.5 + 0.5
        img_np = np.transpose(img.numpy(), (1, 2, 0))

        true_idx = int(labels[i].cpu().item())
        pred_idx = int(preds[i].cpu().item())
        true_name = idx_to_sign_name[true_idx]
        pred_name = idx_to_sign_name[pred_idx]

        ax = plt.subplot(1, n_images, i+1)
        plt.imshow(img_np)
        plt.title(f"T: {true_name}\nP: {pred_name}", fontsize=8)
        plt.axis("off")

    plt.tight_layout()
    plt.show()

print("\nExample predictions on validation images:")
show_example_predictions(val_loader, n_images=5)
